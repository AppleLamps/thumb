---
url: "https://docs.fal.ai/serverless/development/streaming"
title: "Streaming Endpoints - fal"
---

[Skip to main content](https://docs.fal.ai/serverless/development/streaming#content-area)

[fal home page![light logo](https://mintcdn.com/fal-d8505a2e/_1QeqsRe91WUAOCJ/logo/light.svg?fit=max&auto=format&n=_1QeqsRe91WUAOCJ&q=85&s=04c374284984bf56c89974379f02b7a2)![dark logo](https://mintcdn.com/fal-d8505a2e/_1QeqsRe91WUAOCJ/logo/dark.svg?fit=max&auto=format&n=_1QeqsRe91WUAOCJ&q=85&s=b136c77964ac416a72cb0bcba775d7c7)](https://fal.ai/)

Search...

Ctrl KAsk AI

Search...

Navigation

Development

Streaming Endpoints

[![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/home.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/home.svg)Home](https://docs.fal.ai/) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/ar-cube-1.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/ar-cube-1.svg)Model APIs](https://docs.fal.ai/model-apis) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/rocket.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/rocket.svg)Serverless](https://docs.fal.ai/serverless) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/chip.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/chip.svg)Compute](https://docs.fal.ai/compute) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/file-json.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/file-json.svg)Platform APIs](https://docs.fal.ai/platform-apis) [Changelog](https://docs.fal.ai/changelog)

- [Status](https://status.fal.ai/)
- [Community](https://discord.gg/fal-ai)
- [Blog](https://blog.fal.ai/)

- [Introduction](https://docs.fal.ai/serverless)

- [Connect to Cursor](https://docs.fal.ai/serverless/mcp)

##### Getting Started

- [Quick Start](https://docs.fal.ai/serverless/getting-started/quick-start)
- [Deploy Your First Image Generator](https://docs.fal.ai/serverless/getting-started/deploy-your-first-image-generator)
- [Installation & Setup](https://docs.fal.ai/serverless/getting-started/installation)
- [Core Concepts](https://docs.fal.ai/serverless/getting-started/core-concepts)

##### Tutorials

- [Deploy a Text-to-Image Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-image-model)
- [Deploy a Text-to-Video Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-video-model)
- [Deploy a Text-to-Speech Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-speech-model)
- [Deploy a Text-to-Music Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-music-model)
- [Deploy a ComfyUI SDXL Turbo App](https://docs.fal.ai/serverless/tutorials/deploy-comfyui-server)
- [Deploy Multi-GPU Inference](https://docs.fal.ai/serverless/tutorials/deploy-multi-gpu-inference)
- [Deploy Models with Custom Containers](https://docs.fal.ai/serverless/tutorials/deploy-models-with-custom-containers)

##### Deployment & Operations

- [Deploy to Production](https://docs.fal.ai/serverless/deployment-operations/deploy-to-production)
- [Manage Deployments](https://docs.fal.ai/serverless/deployment-operations/manage-deployments)
- [Manage Secrets Securely](https://docs.fal.ai/serverless/deployment-operations/manage-secrets-securely)
- [Monitor Performance](https://docs.fal.ai/serverless/deployment-operations/monitor-performance)
- [Scale Your Application](https://docs.fal.ai/serverless/deployment-operations/scale-your-application)

##### Development

- [Handle Inputs and Outputs](https://docs.fal.ai/serverless/development/handle-inputs-and-outputs)
- [Download Model Weights and Files](https://docs.fal.ai/serverless/development/download-model-weights-and-files)
- [Import Code](https://docs.fal.ai/serverless/development/import-code)
- [Use Persistent Storage](https://docs.fal.ai/serverless/development/use-persistent-storage)
- [Streaming Endpoints](https://docs.fal.ai/serverless/development/streaming)
- [Realtime Endpoints](https://docs.fal.ai/serverless/development/realtime)
- [Test Models and Endpoints](https://docs.fal.ai/serverless/development/test-models-and-endpoints)
- [Use a Custom Container Image](https://docs.fal.ai/serverless/development/use-custom-container-image)
- [Handle request cancellations](https://docs.fal.ai/serverless/development/handle-cancellations)
- [Use KV Store](https://docs.fal.ai/serverless/development/use-kv-store)
- [Add Health Check Endpoint](https://docs.fal.ai/serverless/development/add-health-check-endpoint)

##### Multi-GPU Workloads

- [Overview](https://docs.fal.ai/serverless/distributed/overview)
- [Event Streaming](https://docs.fal.ai/serverless/distributed/streaming)
- [API Reference](https://docs.fal.ai/serverless/distributed/api-reference)

##### Advanced Optimizations

- [Optimize Routing Behavior](https://docs.fal.ai/serverless/optimizations/optimize-routing-behavior)
- [Optimize Model Performance](https://docs.fal.ai/serverless/optimizations/optimize-model-performance)
- [Optimize Startup with Compiled Caches](https://docs.fal.ai/serverless/optimizations/optimize-startup-with-compiled-caches)
- [Optimize Container Images](https://docs.fal.ai/serverless/optimizations/optimize-container-images)

##### Migrations

- [Migrate an External Docker Server](https://docs.fal.ai/serverless/migrations/migrate-external-docker-server)
- [Migrate from Replicate](https://docs.fal.ai/serverless/migrations/migrate-from-replicate)

##### CLI Reference

- [Installation](https://docs.fal.ai/serverless/cli/installation)
- [fal auth](https://docs.fal.ai/serverless/cli/auth)
- fal apps

- [fal deploy](https://docs.fal.ai/serverless/cli/deploy)
- [fal files](https://docs.fal.ai/serverless/cli/files)
- [fal run](https://docs.fal.ai/serverless/cli/run)
- [fal queue](https://docs.fal.ai/serverless/cli/queue)
- [fal keys](https://docs.fal.ai/serverless/cli/keys)
- [fal profile](https://docs.fal.ai/serverless/cli/profile)
- [fal secrets](https://docs.fal.ai/serverless/cli/secrets)
- [fal doctor](https://docs.fal.ai/serverless/cli/doctor)
- [fal create](https://docs.fal.ai/serverless/cli/create)
- [fal runners](https://docs.fal.ai/serverless/cli/runners)

##### Python SDK

- [fal.App Class Reference](https://docs.fal.ai/serverless/python/fal-app-reference)
- [fal.api.SyncServerlessClient](https://docs.fal.ai/serverless/python/client)
- [Python SDK API Reference](https://docs.fal.ai/serverless/python/api-reference)

##### API Reference

- [Platform APIs for Serverless](https://docs.fal.ai/serverless/platform-apis)

On this page

- [When to Use Streaming](https://docs.fal.ai/serverless/development/streaming#when-to-use-streaming)
- [Example: Streaming Intermediate Steps with SDXL](https://docs.fal.ai/serverless/development/streaming#example%3A-streaming-intermediate-steps-with-sdxl)
- [Example Details](https://docs.fal.ai/serverless/development/streaming#example-details)
- [Client-Side Usage](https://docs.fal.ai/serverless/development/streaming#client-side-usage)
- [Python](https://docs.fal.ai/serverless/development/streaming#python)
- [JavaScript](https://docs.fal.ai/serverless/development/streaming#javascript)
- [Key Points](https://docs.fal.ai/serverless/development/streaming#key-points)
- [Next Steps](https://docs.fal.ai/serverless/development/streaming#next-steps)

Streaming allows you to send progressive results to clients as your endpoint processes a request. This is ideal for showing image generation previews, video frame updates, or any operation where users benefit from seeing incremental progress.

**Streaming vs Realtime:** Streaming (SSE) is one-way (server â†’ client) and ideal for progressive output. For bidirectional communication where clients send multiple requests over a persistent connection, see [Realtime Endpoints](https://docs.fal.ai/serverless/development/realtime).

## [â€‹](https://docs.fal.ai/serverless/development/streaming\#when-to-use-streaming)  When to Use Streaming

| Feature | Streaming (SSE) | Realtime (WebSocket) |
| --- | --- | --- |
| **Direction** | One-way (server â†’ client) | Bidirectional (client â†” server) |
| **Connection** | New connection per request | Persistent, reusable |
| **Latency** | Higher (new connection each time) | Lower (connection reuse) |
| **Best for** | Progressive output, previews | Interactive apps, back-to-back requests |
| **Protocol** | JSON over SSE | Binary msgpack |

**Use Streaming when:**

- You want to show progressive output (e.g., image generation previews, video updates)
- Clients send a single request and receive multiple updates
- You donâ€™t need bidirectional communication

**Use [Realtime](https://docs.fal.ai/serverless/development/realtime) when:**

- Users send multiple requests in quick succession (e.g., interactive image editing)
- You need the lowest possible latency between requests
- Youâ€™re building interactive, back-and-forth experiences

## [â€‹](https://docs.fal.ai/serverless/development/streaming\#example:-streaming-intermediate-steps-with-sdxl)  Example: Streaming Intermediate Steps with SDXL

This example shows how to stream intermediate image previews during Stable Diffusion XL generation. It uses a TinyVAE for fast preview decoding and the pipelineâ€™s callback system to capture progress at each step.

Report incorrect code

Copy

Ask AI

```
import fal
import json
import base64
import random
from io import BytesIO
from typing import Any
from queue import Queue

import torch
from pydantic import BaseModel, Field
from fastapi.responses import StreamingResponse

class StreamInput(BaseModel):
    prompt: str = Field(description="The prompt to generate an image from.")
    negative_prompt: str = Field(default="blurry, low quality")
    num_inference_steps: int = Field(default=20, ge=1, le=50)
    width: int = Field(default=1024)
    height: int = Field(default=1024)
    seed: int | None = Field(default=None)

class StreamingSDXLApp(fal.App):
    machine_type = "GPU-A100"

    requirements = [\
        "accelerate==1.4.0",\
        "diffusers==0.30.3",\
        "torch==2.6.0+cu124",\
        "transformers==4.47.1",\
        "--extra-index-url",\
        "https://download.pytorch.org/whl/cu124",\
    ]

    def setup(self):
        from diffusers import AutoencoderTiny, StableDiffusionXLPipeline

        # Load the main SDXL pipeline
        self.pipeline = StableDiffusionXLPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0",
            torch_dtype=torch.float16,
            variant="fp16",
        ).to("cuda")

        # TinyVAE for fast preview generation (much faster than full VAE)
        self.tiny_vae = AutoencoderTiny.from_pretrained(
            "madebyollin/taesdxl",
            torch_dtype=torch.float16,
        ).to("cuda")

    @fal.endpoint("/stream")
    def stream_image(self, input: StreamInput) -> StreamingResponse:
        seed = input.seed if input.seed is not None else random.randint(0, 2**32 - 1)
        generator = torch.Generator(device="cuda").manual_seed(seed)

        # Queue to pass events from callback to the streaming generator
        event_queue: Queue[dict[str, Any] | None] = Queue()

        def pipeline_callback(
            pipe: Any,
            step: int,
            timestep: int,
            callback_kwargs: dict[str, Any],
        ) -> dict[str, Any]:
            """Called after each inference step to stream preview."""
            # Only stream every 5 steps to reduce overhead
            if step > 0 and step % 5 != 0:
                return callback_kwargs

            latents = callback_kwargs["latents"]

            # Decode latents to image using TinyVAE (fast!)
            with torch.no_grad():
                image = self.tiny_vae.decode(
                    latents / self.tiny_vae.config.scaling_factor,
                    return_dict=False,
                )[0]
                image = self.pipeline.image_processor.postprocess(
                    image, output_type="pil"
                )[0]

            # Convert to base64 data URI
            buffer = BytesIO()
            image.save(buffer, format="JPEG", quality=70)
            data_uri = f"data:image/jpeg;base64,{base64.b64encode(buffer.getvalue()).decode()}"

            # Stream the image in the format the playground expects
            event_queue.put({
                "image": {
                    "url": data_uri,
                    "content_type": "image/jpeg",
                }
            })

            return callback_kwargs

        def event_stream():
            import threading

            def run_pipeline():
                # Run the pipeline with our callback
                result = self.pipeline(
                    prompt=input.prompt,
                    negative_prompt=input.negative_prompt,
                    width=input.width,
                    height=input.height,
                    num_inference_steps=input.num_inference_steps,
                    generator=generator,
                    callback_on_step_end=pipeline_callback,
                )

                # Get final image
                final_image = result.images[0]
                buffer = BytesIO()
                final_image.save(buffer, format="JPEG", quality=95)
                data_uri = f"data:image/jpeg;base64,{base64.b64encode(buffer.getvalue()).decode()}"

                # Send final result in the same format
                event_queue.put({
                    "image": {
                        "url": data_uri,
                        "content_type": "image/jpeg",
                    }
                })
                event_queue.put(None)  # Signal completion

            # Run pipeline in background thread
            thread = threading.Thread(target=run_pipeline)
            thread.start()

            # Yield events as they come in
            while True:
                event = event_queue.get()
                if event is None:
                    break
                yield f"data: {json.dumps(event)}\n\n"

            thread.join()

        return StreamingResponse(
            event_stream(),
            media_type="text/event-stream",
        )

    @fal.endpoint("/")
    def generate(self, input: StreamInput) -> dict[str, Any]:
        """Standard non-streaming endpoint."""
        seed = input.seed if input.seed is not None else random.randint(0, 2**32 - 1)
        generator = torch.Generator(device="cuda").manual_seed(seed)

        result = self.pipeline(
            prompt=input.prompt,
            negative_prompt=input.negative_prompt,
            width=input.width,
            height=input.height,
            num_inference_steps=input.num_inference_steps,
            generator=generator,
        )

        return {"image": result.images[0], "seed": seed}
```

### [â€‹](https://docs.fal.ai/serverless/development/streaming\#example-details)  Example Details

This SDXL example demonstrates several techniques:

- **TinyVAE for previews**: Uses `madebyollin/taesdxl` which is ~10x faster than the full VAE for decoding intermediate latents
- **Pipeline callback**: Uses diffusersâ€™ `callback_on_step_end` to capture progress at each denoising step
- **Throttled streaming**: Only streams every 5 steps to balance responsiveness with overhead
- **Thread-safe queue**: Uses a queue to safely pass events from the pipeline thread to the streaming generator

**Playground Image Display Format**For images to display correctly in the fal playground, you **must** include both `url` and `content_type`:

Report incorrect code

Copy

Ask AI

```
{"image": {"url": "data:image/jpeg;base64,...", "content_type": "image/jpeg"}}
```

The playground uses `content_type` to determine how to render the result. Without it, the result will be displayed as raw JSON instead of an image.For multiple images, use an array:

Report incorrect code

Copy

Ask AI

```
{"images": [{"url": "...", "content_type": "image/jpeg"}, ...]}
```

## [â€‹](https://docs.fal.ai/serverless/development/streaming\#client-side-usage)  Client-Side Usage

**Endpoint Path Requirement**The `fal_client.stream()` (Python) and `fal.stream()` (JavaScript) functions automatically append `/stream` to your endpoint ID. This means your app **must** define a streaming endpoint at `/stream` using `@fal.endpoint("/stream")`.For example, calling `fal_client.stream("your-username/your-app-name", ...)` will connect to `https://fal.run/your-username/your-app-name/stream`.

### [â€‹](https://docs.fal.ai/serverless/development/streaming\#python)  Python

Report incorrect code

Copy

Ask AI

```
import fal_client

for event in fal_client.stream(
    "your-username/your-app-name",
    arguments={"prompt": "a beautiful sunset", "num_inference_steps": 20},
):
    # Each event contains {"image": {"url": "data:...", "content_type": "image/jpeg"}}
    image_url = event.get("image", {}).get("url")
    if image_url:
        print(f"Received image preview")
```

### [â€‹](https://docs.fal.ai/serverless/development/streaming\#javascript)  JavaScript

Report incorrect code

Copy

Ask AI

```
import { fal } from "@fal-ai/client";

const stream = await fal.stream("your-username/your-app-name", {
  input: {
    prompt: "a beautiful sunset",
    num_inference_steps: 20,
  },
});

for await (const event of stream) {
  // Each event contains {image: {url: "data:...", content_type: "image/jpeg"}}
  if (event.image?.url) {
    console.log("Received image preview");
    // Display the image: event.image.url is a data URI
  }
}

const finalResult = await stream.done();
```

## [â€‹](https://docs.fal.ai/serverless/development/streaming\#key-points)  Key Points

1. **Use `StreamingResponse`** from FastAPI with `media_type="text/event-stream"`
2. **Format events as SSE**: `yield f"data: {json.dumps(payload)}\n\n"` (note the double newline)
3. **Include `content_type`**: Use `{"image": {"url": "data:...", "content_type": "image/jpeg"}}` for playground display
4. **Throttle streaming**: Donâ€™t stream every intermediate resultâ€”balance responsiveness with overhead
5. **Use lower quality for previews**: Save bandwidth with lower resolution or compression for intermediate results

## [â€‹](https://docs.fal.ai/serverless/development/streaming\#next-steps)  Next Steps

[**Realtime Endpoints** \\
\\
Bidirectional WebSocket communication for interactive apps](https://docs.fal.ai/serverless/development/realtime) [**Distributed Streaming** \\
\\
Stream results from multi-GPU workers](https://docs.fal.ai/serverless/distributed/streaming)

Was this page helpful?

YesNo

[Use Persistent Storage\\
\\
Previous](https://docs.fal.ai/serverless/development/use-persistent-storage) [Realtime Endpoints\\
\\
Next](https://docs.fal.ai/serverless/development/realtime)

Ctrl+I

### ðŸ”’ Need Serverless Access?

Ã—

Don't have access to fal Serverless yet? Request access to deploy your custom models with instant GPU scaling.


[Request Access](https://fal.ai/dashboard/serverless-get-started)

Assistant

Responses are generated using AI and may contain mistakes.

[Create support ticket](mailto:support@fal.ai)