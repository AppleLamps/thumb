---
url: "https://docs.fal.ai/serverless/migrations/migrate-from-replicate"
title: "Migrate from Replicate - fal"
---

[Skip to main content](https://docs.fal.ai/serverless/migrations/migrate-from-replicate#content-area)

[fal home page![light logo](https://mintcdn.com/fal-d8505a2e/_1QeqsRe91WUAOCJ/logo/light.svg?fit=max&auto=format&n=_1QeqsRe91WUAOCJ&q=85&s=04c374284984bf56c89974379f02b7a2)![dark logo](https://mintcdn.com/fal-d8505a2e/_1QeqsRe91WUAOCJ/logo/dark.svg?fit=max&auto=format&n=_1QeqsRe91WUAOCJ&q=85&s=b136c77964ac416a72cb0bcba775d7c7)](https://fal.ai/)

Search...

Ctrl KAsk AI

Search...

Navigation

Migrations

Migrate from Replicate

[![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/home.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/home.svg)Home](https://docs.fal.ai/) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/ar-cube-1.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/ar-cube-1.svg)Model APIs](https://docs.fal.ai/model-apis) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/rocket.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/rocket.svg)Serverless](https://docs.fal.ai/serverless) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/chip.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/chip.svg)Compute](https://docs.fal.ai/compute) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/file-json.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/file-json.svg)Platform APIs](https://docs.fal.ai/platform-apis) [Changelog](https://docs.fal.ai/changelog)

- [Status](https://status.fal.ai/)
- [Community](https://discord.gg/fal-ai)
- [Blog](https://blog.fal.ai/)

- [Introduction](https://docs.fal.ai/serverless)

- [Connect to Cursor](https://docs.fal.ai/serverless/mcp)

##### Getting Started

- [Quick Start](https://docs.fal.ai/serverless/getting-started/quick-start)
- [Deploy Your First Image Generator](https://docs.fal.ai/serverless/getting-started/deploy-your-first-image-generator)
- [Installation & Setup](https://docs.fal.ai/serverless/getting-started/installation)
- [Core Concepts](https://docs.fal.ai/serverless/getting-started/core-concepts)

##### Tutorials

- [Deploy a Text-to-Image Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-image-model)
- [Deploy a Text-to-Video Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-video-model)
- [Deploy a Text-to-Speech Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-speech-model)
- [Deploy a Text-to-Music Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-music-model)
- [Deploy a ComfyUI SDXL Turbo App](https://docs.fal.ai/serverless/tutorials/deploy-comfyui-server)
- [Deploy Multi-GPU Inference](https://docs.fal.ai/serverless/tutorials/deploy-multi-gpu-inference)
- [Deploy Models with Custom Containers](https://docs.fal.ai/serverless/tutorials/deploy-models-with-custom-containers)

##### Deployment & Operations

- [Deploy to Production](https://docs.fal.ai/serverless/deployment-operations/deploy-to-production)
- [Manage Deployments](https://docs.fal.ai/serverless/deployment-operations/manage-deployments)
- [Manage Secrets Securely](https://docs.fal.ai/serverless/deployment-operations/manage-secrets-securely)
- [Monitor Performance](https://docs.fal.ai/serverless/deployment-operations/monitor-performance)
- [Scale Your Application](https://docs.fal.ai/serverless/deployment-operations/scale-your-application)

##### Development

- [Handle Inputs and Outputs](https://docs.fal.ai/serverless/development/handle-inputs-and-outputs)
- [Download Model Weights and Files](https://docs.fal.ai/serverless/development/download-model-weights-and-files)
- [Import Code](https://docs.fal.ai/serverless/development/import-code)
- [Use Persistent Storage](https://docs.fal.ai/serverless/development/use-persistent-storage)
- [Streaming Endpoints](https://docs.fal.ai/serverless/development/streaming)
- [Realtime Endpoints](https://docs.fal.ai/serverless/development/realtime)
- [Test Models and Endpoints](https://docs.fal.ai/serverless/development/test-models-and-endpoints)
- [Use a Custom Container Image](https://docs.fal.ai/serverless/development/use-custom-container-image)
- [Handle request cancellations](https://docs.fal.ai/serverless/development/handle-cancellations)
- [Use KV Store](https://docs.fal.ai/serverless/development/use-kv-store)
- [Add Health Check Endpoint](https://docs.fal.ai/serverless/development/add-health-check-endpoint)

##### Multi-GPU Workloads

- [Overview](https://docs.fal.ai/serverless/distributed/overview)
- [Event Streaming](https://docs.fal.ai/serverless/distributed/streaming)
- [API Reference](https://docs.fal.ai/serverless/distributed/api-reference)

##### Advanced Optimizations

- [Optimize Routing Behavior](https://docs.fal.ai/serverless/optimizations/optimize-routing-behavior)
- [Optimize Model Performance](https://docs.fal.ai/serverless/optimizations/optimize-model-performance)
- [Optimize Startup with Compiled Caches](https://docs.fal.ai/serverless/optimizations/optimize-startup-with-compiled-caches)
- [Optimize Container Images](https://docs.fal.ai/serverless/optimizations/optimize-container-images)

##### Migrations

- [Migrate an External Docker Server](https://docs.fal.ai/serverless/migrations/migrate-external-docker-server)
- [Migrate from Replicate](https://docs.fal.ai/serverless/migrations/migrate-from-replicate)

##### CLI Reference

- [Installation](https://docs.fal.ai/serverless/cli/installation)
- [fal auth](https://docs.fal.ai/serverless/cli/auth)
- fal apps

- [fal deploy](https://docs.fal.ai/serverless/cli/deploy)
- [fal files](https://docs.fal.ai/serverless/cli/files)
- [fal run](https://docs.fal.ai/serverless/cli/run)
- [fal queue](https://docs.fal.ai/serverless/cli/queue)
- [fal keys](https://docs.fal.ai/serverless/cli/keys)
- [fal profile](https://docs.fal.ai/serverless/cli/profile)
- [fal secrets](https://docs.fal.ai/serverless/cli/secrets)
- [fal doctor](https://docs.fal.ai/serverless/cli/doctor)
- [fal create](https://docs.fal.ai/serverless/cli/create)
- [fal runners](https://docs.fal.ai/serverless/cli/runners)

##### Python SDK

- [fal.App Class Reference](https://docs.fal.ai/serverless/python/fal-app-reference)
- [fal.api.SyncServerlessClient](https://docs.fal.ai/serverless/python/client)
- [Python SDK API Reference](https://docs.fal.ai/serverless/python/api-reference)

##### API Reference

- [Platform APIs for Serverless](https://docs.fal.ai/serverless/platform-apis)

On this page

- [Step 1: Generate the Dockerfile with Cog](https://docs.fal.ai/serverless/migrations/migrate-from-replicate#step-1%3A-generate-the-dockerfile-with-cog)
- [Step 2: Adapt the Dockerfile for fal](https://docs.fal.ai/serverless/migrations/migrate-from-replicate#step-2%3A-adapt-the-dockerfile-for-fal)
- [Step 3: Deploy on fal](https://docs.fal.ai/serverless/migrations/migrate-from-replicate#step-3%3A-deploy-on-fal)
- [Step 4: Test Your Deployment](https://docs.fal.ai/serverless/migrations/migrate-from-replicate#step-4%3A-test-your-deployment)
- [Troubleshooting](https://docs.fal.ai/serverless/migrations/migrate-from-replicate#troubleshooting)
- [Conclusion](https://docs.fal.ai/serverless/migrations/migrate-from-replicate#conclusion)

## [â€‹](https://docs.fal.ai/serverless/migrations/migrate-from-replicate\#step-1:-generate-the-dockerfile-with-cog)  Step 1: Generate the Dockerfile with Cog

First, ensure you have Cog installed. If not, follow the instructions on the [Cog GitHub page](https://github.com/replicate/cog).Navigate to your project directory and run:

Report incorrect code

Copy

Ask AI

```
cog debug > Dockerfile
```

This command will generate a `Dockerfile` in the root of your project.

## [â€‹](https://docs.fal.ai/serverless/migrations/migrate-from-replicate\#step-2:-adapt-the-dockerfile-for-fal)  Step 2: Adapt the Dockerfile for fal

With your `Dockerfile` generated, you might need to make a few modifications to ensure compatibility with fal.First, we need to extract Python dependencies and install them in the Docker image. We can do this by copying the dependencies from the Cog file to the Docker image. Hereâ€™s an example of how you can do this:

**Requirements**The following command assumes you have `yq` installed. If not, you can install it using `pip install yq`.
Or follow the instructions on the [yq GitHub page](https://github.com/mikefarah/yq).You might also need to install `jq` if you donâ€™t have it installed. e.g. You can install it using `sudo apt-get install jq` if you are using a Debian-based system. Alternatively, check out the [jq GitHub page](https://github.com/jqlang/jq).

Report incorrect code

Copy

Ask AI

```
yq -e '.build.python_packages | map(select(. != null and . != "")) | map("'"'"'" + . + "'"'"'") | join(" ")' cog.yaml
```

This will give you a list of Python packages that you can install in your Docker image. Using `RUN pip install ...` in your Dockerfile.

**e.g.**â€˜torchâ€™ â€˜torchvisionâ€™ â€˜torchaudioâ€™ â€˜torchsdeâ€™ â€˜einopsâ€™ â€˜transformers>=4.25.1â€™ â€¦

Alternatively, you can write the contents of the `python_packages` to a `requirements.txt` file and install them in the Dockerfile. See the example in [the containerized application page](https://docs.fal.ai/serverless/development/use-custom-container-image).Hereâ€™s a basic example of what your `Dockerfile` might look like:

The example Cog project is [https://github.com/fofr/cog-comfyui](https://github.com/fofr/cog-comfyui).

Report incorrect code

Copy

Ask AI

```
FROM python:3.10.6 as deps
COPY .cog/tmp/build4143857248/cog-0.0.1.dev-py3-none-any.whl /tmp/cog-0.0.1.dev-py3-none-any.whl
RUN --mount=type=cache,target=/root/.cache/pip pip install -t /dep /tmp/cog-0.0.1.dev-py3-none-any.whl
COPY .cog/tmp/build4143857248/requirements.txt /tmp/requirements.txt
RUN --mount=type=cache,target=/root/.cache/pip pip install -t /dep -r /tmp/requirements.txt
RUN --mount=type=cache,target=/root/.cache/pip pip install -t /dep 'torch' 'torchvision' 'torchaudio' 'torchsde' 'einops' 'transformers>=4.25.1' 'safetensors>=0.3.0' 'aiohttp' 'accelerate' 'pyyaml' 'Pillow' 'scipy' 'tqdm' 'psutil' 'spandrel' 'kornia>=0.7.1' 'websocket-client==1.6.3' 'diffusers>=0.25.0' 'albumentations==1.4.3' 'cmake' 'imageio' 'joblib' 'matplotlib' 'pilgram' 'scikit-learn' 'rembg' 'numba' 'pandas' 'numexpr' 'insightface' 'onnx' 'segment-anything' 'piexif' 'ultralytics!=8.0.177' 'timm' 'importlib_metadata' 'opencv-python-headless>=4.0.1.24' 'filelock' 'numpy' 'einops' 'pyyaml' 'scikit-image' 'python-dateutil' 'mediapipe' 'svglib' 'fvcore' 'yapf' 'omegaconf' 'ftfy' 'addict' 'yacs' 'trimesh[easy]' 'librosa' 'color-matcher' 'facexlib'
FROM nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:/usr/local/nvidia/bin
ENV NVIDIA_DRIVER_CAPABILITIES=all
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked set -eux; \
apt-get update -qq && \
apt-get install -qqy --no-install-recommends curl; \
rm -rf /var/lib/apt/lists/*; \
TINI_VERSION=v0.19.0; \
TINI_ARCH="$(dpkg --print-architecture)"; \
curl -sSL -o /sbin/tini "https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini-${TINI_ARCH}"; \
chmod +x /sbin/tini
ENTRYPOINT ["/sbin/tini", "--"]
ENV PATH="/root/.pyenv/shims:/root/.pyenv/bin:$PATH"
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked apt-get update -qq && apt-get install -qqy --no-install-recommends \
	make \
	build-essential \
	libssl-dev \
	zlib1g-dev \
	libbz2-dev \
	libreadline-dev \
	libsqlite3-dev \
	wget \
	curl \
	llvm \
	libncurses5-dev \
	libncursesw5-dev \
	xz-utils \
	tk-dev \
	libffi-dev \
	liblzma-dev \
	git \
	ca-certificates \
	&& rm -rf /var/lib/apt/lists/*
RUN curl -s -S -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash && \
	git clone https://github.com/momo-lab/pyenv-install-latest.git "$(pyenv root)"/plugins/pyenv-install-latest && \
	pyenv install-latest "3.10.6" && \
	pyenv global $(pyenv install-latest --print "3.10.6") && \
	pip install "wheel<1"
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked apt-get update -qq && apt-get install -qqy ffmpeg && rm -rf /var/lib/apt/lists/*
RUN --mount=type=bind,from=deps,source=/dep,target=/dep \
    cp -rf /dep/* $(pyenv prefix)/lib/python*/site-packages; \
    cp -rf /dep/bin/* $(pyenv prefix)/bin; \
    pyenv rehash
RUN curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/download/v0.8.1/pget_linux_x86_64" && chmod +x /usr/local/bin/pget
RUN pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/
# fal platform will inject the necessary mechanisms to run your application.
WORKDIR /src
EXPOSE 5000
CMD ["python", "-m", "cog.server.http"]
COPY . /src
```

And thatâ€™s it! ðŸŽ‰Ensure all dependencies and paths match your projectâ€™s requirements.

## [â€‹](https://docs.fal.ai/serverless/migrations/migrate-from-replicate\#step-3:-deploy-on-fal)  Step 3: Deploy on fal

fal supports deploying Docker-based applications easily. Follow these steps to deploy your Docker container on fal:

1. **Create an account on fal**: If you havenâ€™t already, sign up at [fal](https://fal.ai/).
2. **Create a new project**: In your favorite directory, create a new project and move the `Dockerfile` into it. Create a new Python file with the following content:

Report incorrect code

Copy

Ask AI

```
import fal

from fal.container import ContainerImage
from pathlib import Path

PWD = Path(__file__).resolve().parent

class MyApp(fal.App):
	image = ContainerImage.from_dockerfile(f"{PWD}/Dockerfile")

	def setup(self):
		...

	@fal.endpoint("/")
	def predict(self, input: Input) -> Output:
		# Rest is your imagination.
```

**Converting your app/server**On a serious note, you need to do a little bit of conversion to run your
application. But donâ€™t get intimidated, itâ€™s just a few lines of code. The
structure is of cog server and fal apps are similar, so you can easily adapt
your application to run on fal.

You can see details documentation on how to use fal SDK [here](https://docs.fal.ai/serverless).More information on how to deploy a containerized application can be found [here](https://docs.fal.ai/serverless/development/use-custom-container-image).

## [â€‹](https://docs.fal.ai/serverless/migrations/migrate-from-replicate\#step-4:-test-your-deployment)  Step 4: Test Your Deployment

Once deployed, ensure that everything is working as expected by accessing your application through the URL provided by fal. Monitor logs and performance to make sure the migration was successful.

## [â€‹](https://docs.fal.ai/serverless/migrations/migrate-from-replicate\#troubleshooting)  Troubleshooting

If you encounter any issues during the migration, check the following:

- **Dependencies**: Ensure all required dependencies are listed in your `requirements.txt` or equivalent file.
- **Environment Variables and Build Arguments**: Double-check that all necessary environment variables and build arguments are set correctly in your Dockerfile.
- **Logs**: Use the logging features in fal to diagnose any build or runtime issues.

For further assistance, refer to the [fal Documentation](https://docs.fal.ai/serverless/migrations/migrate-from-replicate#) or reach out to the fal support team.

## [â€‹](https://docs.fal.ai/serverless/migrations/migrate-from-replicate\#conclusion)  Conclusion

Migrating from Replicate to fal can be smooth with proper preparation and testing. This guide provides a straightforward path, but each project may have unique requirements. Adapt these steps as needed to fit your specific use case.For additional help, join our community on [Discord](https://discord.com/invite/fal-ai) or contact our support team.

Was this page helpful?

YesNo

[Migrate an External Docker Server\\
\\
Previous](https://docs.fal.ai/serverless/migrations/migrate-external-docker-server) [Installation\\
\\
Next](https://docs.fal.ai/serverless/cli/installation)

Ctrl+I

### ðŸ”’ Need Serverless Access?

Ã—

Don't have access to fal Serverless yet? Request access to deploy your custom models with instant GPU scaling.


[Request Access](https://fal.ai/dashboard/serverless-get-started)

Assistant

Responses are generated using AI and may contain mistakes.

[Create support ticket](mailto:support@fal.ai)