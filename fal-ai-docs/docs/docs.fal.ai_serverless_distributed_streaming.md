---
url: "https://docs.fal.ai/serverless/distributed/streaming"
title: "Event Streaming - fal"
---

[Skip to main content](https://docs.fal.ai/serverless/distributed/streaming#content-area)

[fal home page![light logo](https://mintcdn.com/fal-d8505a2e/_1QeqsRe91WUAOCJ/logo/light.svg?fit=max&auto=format&n=_1QeqsRe91WUAOCJ&q=85&s=04c374284984bf56c89974379f02b7a2)![dark logo](https://mintcdn.com/fal-d8505a2e/_1QeqsRe91WUAOCJ/logo/dark.svg?fit=max&auto=format&n=_1QeqsRe91WUAOCJ&q=85&s=b136c77964ac416a72cb0bcba775d7c7)](https://fal.ai/)

Search...

Ctrl KAsk AI

Search...

Navigation

Multi-GPU Workloads

Event Streaming

[![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/home.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/home.svg)Home](https://docs.fal.ai/) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/ar-cube-1.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/ar-cube-1.svg)Model APIs](https://docs.fal.ai/model-apis) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/rocket.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/rocket.svg)Serverless](https://docs.fal.ai/serverless) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/chip.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/chip.svg)Compute](https://docs.fal.ai/compute) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/file-json.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/file-json.svg)Platform APIs](https://docs.fal.ai/platform-apis) [Changelog](https://docs.fal.ai/changelog)

- [Status](https://status.fal.ai/)
- [Community](https://discord.gg/fal-ai)
- [Blog](https://blog.fal.ai/)

- [Introduction](https://docs.fal.ai/serverless)

- [Connect to Cursor](https://docs.fal.ai/serverless/mcp)

##### Getting Started

- [Quick Start](https://docs.fal.ai/serverless/getting-started/quick-start)
- [Deploy Your First Image Generator](https://docs.fal.ai/serverless/getting-started/deploy-your-first-image-generator)
- [Installation & Setup](https://docs.fal.ai/serverless/getting-started/installation)
- [Core Concepts](https://docs.fal.ai/serverless/getting-started/core-concepts)

##### Tutorials

- [Deploy a Text-to-Image Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-image-model)
- [Deploy a Text-to-Video Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-video-model)
- [Deploy a Text-to-Speech Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-speech-model)
- [Deploy a Text-to-Music Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-music-model)
- [Deploy a ComfyUI SDXL Turbo App](https://docs.fal.ai/serverless/tutorials/deploy-comfyui-server)
- [Deploy Multi-GPU Inference](https://docs.fal.ai/serverless/tutorials/deploy-multi-gpu-inference)
- [Deploy Models with Custom Containers](https://docs.fal.ai/serverless/tutorials/deploy-models-with-custom-containers)

##### Deployment & Operations

- [Deploy to Production](https://docs.fal.ai/serverless/deployment-operations/deploy-to-production)
- [Manage Deployments](https://docs.fal.ai/serverless/deployment-operations/manage-deployments)
- [Manage Secrets Securely](https://docs.fal.ai/serverless/deployment-operations/manage-secrets-securely)
- [Monitor Performance](https://docs.fal.ai/serverless/deployment-operations/monitor-performance)
- [Scale Your Application](https://docs.fal.ai/serverless/deployment-operations/scale-your-application)

##### Development

- [Handle Inputs and Outputs](https://docs.fal.ai/serverless/development/handle-inputs-and-outputs)
- [Download Model Weights and Files](https://docs.fal.ai/serverless/development/download-model-weights-and-files)
- [Import Code](https://docs.fal.ai/serverless/development/import-code)
- [Use Persistent Storage](https://docs.fal.ai/serverless/development/use-persistent-storage)
- [Streaming Endpoints](https://docs.fal.ai/serverless/development/streaming)
- [Realtime Endpoints](https://docs.fal.ai/serverless/development/realtime)
- [Test Models and Endpoints](https://docs.fal.ai/serverless/development/test-models-and-endpoints)
- [Use a Custom Container Image](https://docs.fal.ai/serverless/development/use-custom-container-image)
- [Handle request cancellations](https://docs.fal.ai/serverless/development/handle-cancellations)
- [Use KV Store](https://docs.fal.ai/serverless/development/use-kv-store)
- [Add Health Check Endpoint](https://docs.fal.ai/serverless/development/add-health-check-endpoint)

##### Multi-GPU Workloads

- [Overview](https://docs.fal.ai/serverless/distributed/overview)
- [Event Streaming](https://docs.fal.ai/serverless/distributed/streaming)
- [API Reference](https://docs.fal.ai/serverless/distributed/api-reference)

##### Advanced Optimizations

- [Optimize Routing Behavior](https://docs.fal.ai/serverless/optimizations/optimize-routing-behavior)
- [Optimize Model Performance](https://docs.fal.ai/serverless/optimizations/optimize-model-performance)
- [Optimize Startup with Compiled Caches](https://docs.fal.ai/serverless/optimizations/optimize-startup-with-compiled-caches)
- [Optimize Container Images](https://docs.fal.ai/serverless/optimizations/optimize-container-images)

##### Migrations

- [Migrate an External Docker Server](https://docs.fal.ai/serverless/migrations/migrate-external-docker-server)
- [Migrate from Replicate](https://docs.fal.ai/serverless/migrations/migrate-from-replicate)

##### CLI Reference

- [Installation](https://docs.fal.ai/serverless/cli/installation)
- [fal auth](https://docs.fal.ai/serverless/cli/auth)
- fal apps

- [fal deploy](https://docs.fal.ai/serverless/cli/deploy)
- [fal files](https://docs.fal.ai/serverless/cli/files)
- [fal run](https://docs.fal.ai/serverless/cli/run)
- [fal queue](https://docs.fal.ai/serverless/cli/queue)
- [fal keys](https://docs.fal.ai/serverless/cli/keys)
- [fal profile](https://docs.fal.ai/serverless/cli/profile)
- [fal secrets](https://docs.fal.ai/serverless/cli/secrets)
- [fal doctor](https://docs.fal.ai/serverless/cli/doctor)
- [fal create](https://docs.fal.ai/serverless/cli/create)
- [fal runners](https://docs.fal.ai/serverless/cli/runners)

##### Python SDK

- [fal.App Class Reference](https://docs.fal.ai/serverless/python/fal-app-reference)
- [fal.api.SyncServerlessClient](https://docs.fal.ai/serverless/python/client)
- [Python SDK API Reference](https://docs.fal.ai/serverless/python/api-reference)

##### API Reference

- [Platform APIs for Serverless](https://docs.fal.ai/serverless/platform-apis)

On this page

- [How Streaming Works](https://docs.fal.ai/serverless/distributed/streaming#how-streaming-works)
- [Basic Streaming Example](https://docs.fal.ai/serverless/distributed/streaming#basic-streaming-example)
- [1\. Stream from Workers](https://docs.fal.ai/serverless/distributed/streaming#1-stream-from-workers)
- [2\. Create Streaming Endpoint](https://docs.fal.ai/serverless/distributed/streaming#2-create-streaming-endpoint)
- [3\. Consume Stream from Client](https://docs.fal.ai/serverless/distributed/streaming#3-consume-stream-from-client)
- [Advanced: Streaming with Gather](https://docs.fal.ai/serverless/distributed/streaming#advanced%3A-streaming-with-gather)
- [Best Practices](https://docs.fal.ai/serverless/distributed/streaming#best-practices)
- [1\. Stream Only from Rank 0](https://docs.fal.ai/serverless/distributed/streaming#1-stream-only-from-rank-0)
- [2\. Throttle Stream Frequency](https://docs.fal.ai/serverless/distributed/streaming#2-throttle-stream-frequency)
- [3\. Use Synchronization](https://docs.fal.ai/serverless/distributed/streaming#3-use-synchronization)
- [4\. Keep Payloads Small](https://docs.fal.ai/serverless/distributed/streaming#4-keep-payloads-small)
- [5\. Handle Images Efficiently](https://docs.fal.ai/serverless/distributed/streaming#5-handle-images-efficiently)
- [Complete Example](https://docs.fal.ai/serverless/distributed/streaming#complete-example)
- [Next Steps](https://docs.fal.ai/serverless/distributed/streaming#next-steps)

Streaming allows you to send intermediate results from your distributed workers back to the client in real-time. This is particularly useful for long-running operations like image generation, video creation, or model training where users benefit from seeing progress updates.

For a complete working example of streaming with multi-GPU inference, see the [Parallel SDXL Tutorial](https://docs.fal.ai/serverless/tutorials/deploy-multi-gpu-inference).

## [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#how-streaming-works)  How Streaming Works

With `fal.distributed`, you can stream results from workers during execution:

Multiple GPUs

Request

Stream events

Stream events

Stream events

Server-Sent Events

Client

(Browser/API)

fal.App

Endpoint

DistributedRunner

Worker 0

add\_streaming\_result()

Worker 1

add\_streaming\_result()

## [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#basic-streaming-example)  Basic Streaming Example

### [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#1-stream-from-workers)  1\. Stream from Workers

In your `DistributedWorker`, use `add_streaming_result()` to send intermediate results:

Report incorrect code

Copy

Ask AI

```
from fal.distributed import DistributedWorker
import torch.distributed as dist

class StreamingWorker(DistributedWorker):
    def __call__(self, prompt: str, steps: int = 20):
        for step in range(steps):
            # Do some processing
            result = self.model.step(prompt)

            # Only rank 0 streams to avoid duplicates
            if self.rank == 0:
                self.add_streaming_result({
                    "step": step,
                    "progress": (step + 1) / steps,
                    "message": f"Processing step {step + 1}/{steps}"
                }, as_text_event=True)

        # Return final result
        return {"output": final_result}
```

**Key points:**

- `add_streaming_result()`: Sends data to the client
- `as_text_event=True`: Formats as Server-Sent Events (SSE)
- Only rank 0 should stream to avoid duplicate messages

### [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#2-create-streaming-endpoint)  2\. Create Streaming Endpoint

Define an endpoint that returns a `StreamingResponse`:

Report incorrect code

Copy

Ask AI

```
import fal
from fal.distributed import DistributedRunner
from fastapi.responses import StreamingResponse

class MyApp(fal.App):
    num_gpus = 2

    def setup(self):
        self.runner = DistributedRunner(
            worker_cls=StreamingWorker,
            world_size=self.num_gpus,
        )

    @fal.endpoint("/stream")
    async def stream(self, request: MyRequest) -> StreamingResponse:
        """Endpoint that streams results"""
        return StreamingResponse(
            self.runner.stream(
                request.dict(),
                as_text_events=True,
            ),
            media_type="text/event-stream",
        )
```

### [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#3-consume-stream-from-client)  3\. Consume Stream from Client

**JavaScript/TypeScript:**

Report incorrect code

Copy

Ask AI

```
const response = await fetch('https://your-app.fal.run/stream', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ prompt: "A sunset", steps: 20 })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  const text = decoder.decode(value);
  const events = text.split('\n\n');

  for (const event of events) {
    if (event.startsWith('data: ')) {
      const data = JSON.parse(event.slice(6));
      console.log(`Step ${data.step}: ${data.progress * 100}%`);
    }
  }
}
```

**Python:**

Report incorrect code

Copy

Ask AI

```
import fal_client

for event in fal_client.stream(
    "username/app-name",
    arguments={"prompt": "A sunset", "steps": 20}
    # path="/stream"  # Optional: defaults to "/stream", change if your endpoint uses a different path
):
    print(f"Step {event['step']}: {event['progress'] * 100}%")
```

If your endpoint uses a path other than `/stream`, specify it with the `path` parameter to match your `@fal.endpoint()` decorator.

## [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#advanced:-streaming-with-gather)  Advanced: Streaming with Gather

Stream intermediate results from all GPUs and combine them:

Report incorrect code

Copy

Ask AI

```
class MultiGPUStreamingWorker(DistributedWorker):
    def __call__(self, prompt: str, num_steps: int = 20):
        for step in range(0, num_steps, 5):  # Stream every 5 steps
            # Generate intermediate result on this GPU
            intermediate = self.model.step(prompt)

            # Gather from all workers
            if self.rank == 0:
                gather_list = [\
                    torch.zeros_like(intermediate, device=self.device)\
                    for _ in range(self.world_size)\
                ]
            else:
                gather_list = None

            dist.gather(intermediate, gather_list, dst=0)

            # Only rank 0 streams the combined result
            if self.rank == 0:
                combined = self.combine_results(gather_list)
                self.add_streaming_result({
                    "step": step,
                    "preview": combined,
                    "num_gpus": self.world_size,
                }, as_text_event=True)

            # Synchronize before next step
            dist.barrier()

        return {"final": final_result}
```

## [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#best-practices)  Best Practices

### [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#1-stream-only-from-rank-0)  1\. Stream Only from Rank 0

Avoid duplicate messages by only streaming from the main worker:

Report incorrect code

Copy

Ask AI

```
if self.rank == 0:
    self.add_streaming_result(data, as_text_event=True)
```

### [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#2-throttle-stream-frequency)  2\. Throttle Stream Frequency

Donâ€™t stream on every iteration - use intervals:

Report incorrect code

Copy

Ask AI

```
if step % 5 == 0:  # Every 5 steps
    self.add_streaming_result(...)
```

### [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#3-use-synchronization)  3\. Use Synchronization

Synchronize workers after streaming to maintain consistency:

Report incorrect code

Copy

Ask AI

```
if self.rank == 0:
    self.add_streaming_result(data, as_text_event=True)

dist.barrier()  # Wait for all workers
```

### [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#4-keep-payloads-small)  4\. Keep Payloads Small

Stream minimal data for responsiveness:

Report incorrect code

Copy

Ask AI

```
# Good: Small progress updates
self.add_streaming_result({
    "step": step,
    "progress": 0.5,
})

# Avoid: Large data in every update
# self.add_streaming_result({"large_array": [...]})
```

### [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#5-handle-images-efficiently)  5\. Handle Images Efficiently

For streaming images, use base64 encoding:

Report incorrect code

Copy

Ask AI

```
import base64
import io

# Convert PIL image to base64
buffer = io.BytesIO()
image.save(buffer, format="JPEG")
image_b64 = base64.b64encode(buffer.getvalue()).decode()

self.add_streaming_result({
    "preview": f"data:image/jpeg;base64,{image_b64}"
}, as_text_event=True)
```

## [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#complete-example)  Complete Example

See the [Multi-GPU Inference Tutorial](https://docs.fal.ai/serverless/tutorials/deploy-multi-gpu-inference) for a complete working example with streaming, including:

- Real-time preview generation
- Progress updates every 5 steps
- Gathering results from multiple GPUs
- Progressive blur effects during generation

## [â€‹](https://docs.fal.ai/serverless/distributed/streaming\#next-steps)  Next Steps

[**Multi-GPU Inference Tutorial** \\
\\
Complete streaming example with SDXL](https://docs.fal.ai/serverless/tutorials/deploy-multi-gpu-inference) [**Real-time Endpoints** \\
\\
Learn about falâ€™s real-time framework](https://docs.fal.ai/serverless/development/realtime)

Was this page helpful?

YesNo

[Overview\\
\\
Previous](https://docs.fal.ai/serverless/distributed/overview) [API Reference\\
\\
Next](https://docs.fal.ai/serverless/distributed/api-reference)

Ctrl+I

### ðŸ”’ Need Serverless Access?

Ã—

Don't have access to fal Serverless yet? Request access to deploy your custom models with instant GPU scaling.


[Request Access](https://fal.ai/dashboard/serverless-get-started)

Assistant

Responses are generated using AI and may contain mistakes.

[Create support ticket](mailto:support@fal.ai)