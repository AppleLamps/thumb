---
url: "https://docs.fal.ai/serverless/development/use-persistent-storage"
title: "Use Persistent Storage - fal"
---

[Skip to main content](https://docs.fal.ai/serverless/development/use-persistent-storage#content-area)

[fal home page![light logo](https://mintcdn.com/fal-d8505a2e/_1QeqsRe91WUAOCJ/logo/light.svg?fit=max&auto=format&n=_1QeqsRe91WUAOCJ&q=85&s=04c374284984bf56c89974379f02b7a2)![dark logo](https://mintcdn.com/fal-d8505a2e/_1QeqsRe91WUAOCJ/logo/dark.svg?fit=max&auto=format&n=_1QeqsRe91WUAOCJ&q=85&s=b136c77964ac416a72cb0bcba775d7c7)](https://fal.ai/)

Search...

Ctrl KAsk AI

Search...

Navigation

Development

Use Persistent Storage

[![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/home.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/home.svg)Home](https://docs.fal.ai/) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/ar-cube-1.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/ar-cube-1.svg)Model APIs](https://docs.fal.ai/model-apis) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/rocket.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/rocket.svg)Serverless](https://docs.fal.ai/serverless) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/chip.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/chip.svg)Compute](https://docs.fal.ai/compute) [![https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/file-json.svg](https://mintlify.s3.us-west-1.amazonaws.com/fal-d8505a2e/images/icons/file-json.svg)Platform APIs](https://docs.fal.ai/platform-apis) [Changelog](https://docs.fal.ai/changelog)

- [Status](https://status.fal.ai/)
- [Community](https://discord.gg/fal-ai)
- [Blog](https://blog.fal.ai/)

- [Introduction](https://docs.fal.ai/serverless)

- [Connect to Cursor](https://docs.fal.ai/serverless/mcp)

##### Getting Started

- [Quick Start](https://docs.fal.ai/serverless/getting-started/quick-start)
- [Deploy Your First Image Generator](https://docs.fal.ai/serverless/getting-started/deploy-your-first-image-generator)
- [Installation & Setup](https://docs.fal.ai/serverless/getting-started/installation)
- [Core Concepts](https://docs.fal.ai/serverless/getting-started/core-concepts)

##### Tutorials

- [Deploy a Text-to-Image Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-image-model)
- [Deploy a Text-to-Video Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-video-model)
- [Deploy a Text-to-Speech Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-speech-model)
- [Deploy a Text-to-Music Model](https://docs.fal.ai/serverless/tutorials/deploy-text-to-music-model)
- [Deploy a ComfyUI SDXL Turbo App](https://docs.fal.ai/serverless/tutorials/deploy-comfyui-server)
- [Deploy Multi-GPU Inference](https://docs.fal.ai/serverless/tutorials/deploy-multi-gpu-inference)
- [Deploy Models with Custom Containers](https://docs.fal.ai/serverless/tutorials/deploy-models-with-custom-containers)

##### Deployment & Operations

- [Deploy to Production](https://docs.fal.ai/serverless/deployment-operations/deploy-to-production)
- [Manage Deployments](https://docs.fal.ai/serverless/deployment-operations/manage-deployments)
- [Manage Secrets Securely](https://docs.fal.ai/serverless/deployment-operations/manage-secrets-securely)
- [Monitor Performance](https://docs.fal.ai/serverless/deployment-operations/monitor-performance)
- [Scale Your Application](https://docs.fal.ai/serverless/deployment-operations/scale-your-application)

##### Development

- [Handle Inputs and Outputs](https://docs.fal.ai/serverless/development/handle-inputs-and-outputs)
- [Download Model Weights and Files](https://docs.fal.ai/serverless/development/download-model-weights-and-files)
- [Import Code](https://docs.fal.ai/serverless/development/import-code)
- [Use Persistent Storage](https://docs.fal.ai/serverless/development/use-persistent-storage)
- [Streaming Endpoints](https://docs.fal.ai/serverless/development/streaming)
- [Realtime Endpoints](https://docs.fal.ai/serverless/development/realtime)
- [Test Models and Endpoints](https://docs.fal.ai/serverless/development/test-models-and-endpoints)
- [Use a Custom Container Image](https://docs.fal.ai/serverless/development/use-custom-container-image)
- [Handle request cancellations](https://docs.fal.ai/serverless/development/handle-cancellations)
- [Use KV Store](https://docs.fal.ai/serverless/development/use-kv-store)
- [Add Health Check Endpoint](https://docs.fal.ai/serverless/development/add-health-check-endpoint)

##### Multi-GPU Workloads

- [Overview](https://docs.fal.ai/serverless/distributed/overview)
- [Event Streaming](https://docs.fal.ai/serverless/distributed/streaming)
- [API Reference](https://docs.fal.ai/serverless/distributed/api-reference)

##### Advanced Optimizations

- [Optimize Routing Behavior](https://docs.fal.ai/serverless/optimizations/optimize-routing-behavior)
- [Optimize Model Performance](https://docs.fal.ai/serverless/optimizations/optimize-model-performance)
- [Optimize Startup with Compiled Caches](https://docs.fal.ai/serverless/optimizations/optimize-startup-with-compiled-caches)
- [Optimize Container Images](https://docs.fal.ai/serverless/optimizations/optimize-container-images)

##### Migrations

- [Migrate an External Docker Server](https://docs.fal.ai/serverless/migrations/migrate-external-docker-server)
- [Migrate from Replicate](https://docs.fal.ai/serverless/migrations/migrate-from-replicate)

##### CLI Reference

- [Installation](https://docs.fal.ai/serverless/cli/installation)
- [fal auth](https://docs.fal.ai/serverless/cli/auth)
- fal apps

- [fal deploy](https://docs.fal.ai/serverless/cli/deploy)
- [fal files](https://docs.fal.ai/serverless/cli/files)
- [fal run](https://docs.fal.ai/serverless/cli/run)
- [fal queue](https://docs.fal.ai/serverless/cli/queue)
- [fal keys](https://docs.fal.ai/serverless/cli/keys)
- [fal profile](https://docs.fal.ai/serverless/cli/profile)
- [fal secrets](https://docs.fal.ai/serverless/cli/secrets)
- [fal doctor](https://docs.fal.ai/serverless/cli/doctor)
- [fal create](https://docs.fal.ai/serverless/cli/create)
- [fal runners](https://docs.fal.ai/serverless/cli/runners)

##### Python SDK

- [fal.App Class Reference](https://docs.fal.ai/serverless/python/fal-app-reference)
- [fal.api.SyncServerlessClient](https://docs.fal.ai/serverless/python/client)
- [Python SDK API Reference](https://docs.fal.ai/serverless/python/api-reference)

##### API Reference

- [Platform APIs for Serverless](https://docs.fal.ai/serverless/platform-apis)

On this page

- [Usage Considerations](https://docs.fal.ai/serverless/development/use-persistent-storage#usage-considerations)
- [Concurrency](https://docs.fal.ai/serverless/development/use-persistent-storage#concurrency)
- [Sequential vs parallel reading](https://docs.fal.ai/serverless/development/use-persistent-storage#sequential-vs-parallel-reading)
- [Filesystem internals](https://docs.fal.ai/serverless/development/use-persistent-storage#filesystem-internals)
- [Persistence](https://docs.fal.ai/serverless/development/use-persistent-storage#persistence)
- [Caching](https://docs.fal.ai/serverless/development/use-persistent-storage#caching)
- [Alternative: KVStore for Small Key-Value Data](https://docs.fal.ai/serverless/development/use-persistent-storage#alternative%3A-kvstore-for-small-key-value-data)

Report incorrect code

Copy

Ask AI

```
import fal
from pathlib import Path

DATA_DIR = Path("/data/mnist")

class FalModel(fal.App):
    requirements = ["torch>=2.0.0", "torchvision"]
    machine_type = "GPU"

    def setup(self):
        import torch
        from torchvision import datasets

        already_present = DATA_DIR.exists()
        if already_present:
            print("Test data is already downloaded, skipping download!")

        test_data = datasets.FashionMNIST(
            root=DATA_DIR,
            train=False,
            download=not already_present,
        )
        ...
```

When you invoke this app for the first time, you will notice that Torch downloads the test dataset. However, subsequent invocations - even those not covered by the invocationâ€™s `keep_alive` \- will skip the download and proceed directly to your logic.

**Implementation note**For HF-related libraries, fal ensures all downloaded models are persisted to
avoid re-downloads when running ML inference workloads. No need to customize
the output path for `transformers` or `diffusers`.

## [â€‹](https://docs.fal.ai/serverless/development/use-persistent-storage\#usage-considerations)  Usage Considerations

Since the `/data` is a distributed filesystem, there are a couple of caveats to keep in mind.

### [â€‹](https://docs.fal.ai/serverless/development/use-persistent-storage\#concurrency)  Concurrency

`/data` is shared across all runners, so you should be mindful of how you access common files from your runners to avoid race conditions. For example, when creating or
downloading a file, you should use a temporary unique path beside the final destination until the file is fully downloaded or created and only then move it into place,
which makes the operation quasi-atomic and avoids the situation where another runner tries to use an incomplete file.

Report incorrect code

Copy

Ask AI

```
import fal
import tempfile
import os
from pathlib import Path

WEIGHTS_URL = "https://example.com/weights.safetensors"
WEIGHTS_FILE = Path("/data/weights.safetensors")

class FalModel(
    fal.App,
    ...,
):
    def setup(self):
        # Create temporary file right beside the final destination, so that we can
        # use os.rename to move the file into place with 1 system call within the
        # same filesystem.
        with tempfile.NamedTemporaryFile(delete=False, dir="/data") as temp_file:
            # download the weights
            ...
            # Move the weights to the final destination.
            os.rename(temp_file.name, WEIGHTS_FILE)
        ...
```

### [â€‹](https://docs.fal.ai/serverless/development/use-persistent-storage\#sequential-vs-parallel-reading)  Sequential vs parallel reading

Avoid reading multiple files sequentially, especially if they are small. Sequential reads do not take full advantage of the massively parallel caching and downloading capabilities of the file system.Total throughput is always higher when multiple files are read in parallel.If the process of loading model weights into memory is sequential, you can greatly speed it up by pre-reading all the files with code like this:

Report incorrect code

Copy

Ask AI

```
MODEL_DIR = "/data/models/deepseek-ai"

subprocess.check_call(
    f"find '{MODEL_DIR}' -type f | "
    "xargs -P 32 -I {} cat {} > /dev/null",
    shell=True
)
```

## [â€‹](https://docs.fal.ai/serverless/development/use-persistent-storage\#filesystem-internals)  Filesystem internals

### [â€‹](https://docs.fal.ai/serverless/development/use-persistent-storage\#persistence)  Persistence

Each file is split into 4MB chunks (identified by their hash) which are saved into a global object store. A metadata layer stores the relation between file paths and chunks, ensuring that non-content operations (e.g. renames) are atomic and fast.

### [â€‹](https://docs.fal.ai/serverless/development/use-persistent-storage\#caching)  Caching

The `/data` volume features 2 caching layers:

- Local cache on the node (RAID 5 on NVME drives). Typical speeds are 10-15 GB/s. A cache miss falls through to the distributed cache.
- Distributed cache amongst all servers in the local datacenter, where chunks are evenly distributed. Access is typically very fast, using a 100 GBps network. Typical speeds are 6-8 GB/s. A cache miss falls through to the object store.

This is what happens during a file read:

1. The metadata service is consulted to obtain the chunk IDs linked to the file path
2. The file system tries to find the chunks in the local cache. Available chunks are directly read.
3. On cache miss, the distributed cache is tried. Available chunks are streamed in parallel (from multiple nodes) and also saved into the local cache.
4. On distributed cache miss, the missing chunks are downloaded from the backing object store by the individual nodes responsible for each chunk.
Typical speeds are 1.5-8 GB/s depending on datacenter size and number of chunks.
The target server synchronously streams the chunks to its local cache as they are fetched.
If the chunks are not available in the object store, the read operation blocks until they appear. This likely means that the file was written recently and the source server is still uploading data (see below).

This is what happens during a file write:

1. While a file is being written, it is buffered in memory/local disk (already in chunks).
2. When the file is closed, the chunks are moved to the local cache and are written to the metadata layer. At this point, another process on the same server can access the file.
3. The server starts sharing the chunks with the other members of the distributed cache. Once this is done, the file is available to other servers in the same datacenter.
4. In parallel to the above, the server also starts uploading the chunks in the background to the object store. Speeds are typically 300-500 MB/s. Once the upload is done, the file is available to all data centers.

## [â€‹](https://docs.fal.ai/serverless/development/use-persistent-storage\#alternative:-kvstore-for-small-key-value-data)  Alternative: KVStore for Small Key-Value Data

For storing small pieces of state (configuration, cached API responses, session data), fal also provides [KVStore](https://docs.fal.ai/serverless/development/use-kv-store) \- a simple key-value storage with zero setup. KVStore is designed for data up to 25 MB per value and provides faster access for small data compared to file-based storage.Use `/data` for large files and model weights. Use KVStore for small configuration and state data.

Was this page helpful?

YesNo

[Import Code\\
\\
Previous](https://docs.fal.ai/serverless/development/import-code) [Streaming Endpoints\\
\\
Next](https://docs.fal.ai/serverless/development/streaming)

Ctrl+I

### ðŸ”’ Need Serverless Access?

Ã—

Don't have access to fal Serverless yet? Request access to deploy your custom models with instant GPU scaling.


[Request Access](https://fal.ai/dashboard/serverless-get-started)

Assistant

Responses are generated using AI and may contain mistakes.

[Create support ticket](mailto:support@fal.ai)